# -*- coding: utf-8 -*-
"""func_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bwok0W1S7wFM9gmeaJYZo-ezHEHuJgMS
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from math import ceil
import time
from scipy.stats import norm
from tqdm import tqdm_notebook as tqdm 
from pylab import MaxNLocator
from func_plot import labs, central_trend
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn import metrics

class Classifier:
    '''
    Recebe um modelo ML e separa em variáveis preditoras e variável de resposta 
    (x e y, respectivamente) e separa entre dados de treinamento e dados de
    teste.
    REaliza a validação cruzada e imprime os resultados, além de plotar a curva
    roc, histogramas de métricas e média da matriz de confusão.

    '''
    def __init__(self,
                 estimator,
                 df:pd.DataFrame,
                 seed:int = 324551,
                 target_variable='ICU',
                  **estimator_args):
        '''
        Parâmetros Construtor:
        ---------------------
        estimator : modelo de machine learning com que possua um método fit(), 
        predict() e predict_proba()
        df : DataFrame com os dados a serem previstos, tipo : pd.DataFrame
        seed : número que define a semente aleatória utilizada em todos os 
        métodos, tipo : int, padrão : 324551
        target_variable : nome da variável de resposta(alvo), 
        tipo : str, padrão : 'ICU'
        **estimator_args : parâmetros a serem passados para o modelo se o mesmo 
        ainda não ter sido instanciado
    
        Atributos definidos no construtor:
        ---------
        seed : número inteiro que define a aleatoriedade
        x : conjunto de dados sem a váriavel alvo
        y : conjunto de dados com as respostas da variável alvo
        estimator : modelo de machine learning
        '''
        self.seed = seed
        df = df.sample(frac=1, random_state=self.seed).reset_index(drop=True)
        self.x = df.drop(target_variable, axis=1)
        self.y = df[target_variable]
        if callable(estimator):
            self.estimator = estimator(random_state=self.seed, **estimator_args)
        else:
            self.estimator = estimator     
    
    def cross_val(self, 
                  scoring:list = ['f1', 'roc_auc', 'precision', 'recall', 'accuracy'],
                  n_splits = 5,
                  n_repeats = 10,
                  report=True):
        '''
        Realiza uma validação cruzada do tipo RepeatedStratifiedKFold e salva os
        resultados das métricas passadas no parâmetro 
        scoring
        
        Parâmetros:
        ----------
        scoring : lista os nomes das métricas que serão calculadas na validação 
        cruzada, essa lista aceita as 
                  seguintes métricas : {'f1','roc_auc','precision','recall','accuracy'},
                  tipo : list, padrão : ['f1', 'roc_auc', 'precision', 'recall', 'accuracy'],
        n_splits : número inteiro indicando a quantidade de divisões realizadas no dataset na hora da validação cruzada, 
                   tipo : int, padrão : 5
        n_repeats : número inteiro indicando a quantidade de repetições realizadas da validação cruzada, 
                    tipo : int, padrão : 10
        report : valor booleano indicando a chamada da função report que imprime os resultados, 
                 tipo : bool, padrão : True
        
        Atributos definidos:
        --------------------
        n_splits: número inteiro indicando a quantidade de divisões realizadas no dataset na hora da validação cruzada
        n_repeats : número inteiro indicando a quantidade de repetições realizadas da validação cruzada
        len : número inteiro indicando a quantidade total de treinamentos realizados, igual a n_splits * n_repeats
        scores : dicionário com os resultados de todos os treinamentos realizados na validação cruzada
        means : dicionário com as médias de todas as métricas calculadas na validação cruzada
        confusion_matrix_mean : média das matrizes de confusão geradas em cada FOLD da validação cruzada
        stds : dicionário com os desvios padrões amostrais de todas as métricas calculadas na validação cruzada
        time_mean : lista com os tempos médios de treinamento
        tprs_mean : lista com as médias dos valores verdadeiros positivos da curva ROC
        tprs_std : lista com os desvios padrões amostrais dos valores verdadeiros positivos da curva ROC
        fpr_mean : lista com os valores falsos positivos da curva ROC
        '''
        
        self.n_splits = n_splits
        self.n_repeats = n_repeats
        self.len = n_splits * n_repeats
        self.scores = {metric:[] for metric in ['f1', 'roc_auc', 'precision', 'recall', 'accuracy']}
        
        confusion_matrixs_sum = np.zeros([2,2])

        self.fpr_mean = np.linspace(0, 1, 100)
        tprs = []

        time_list = []

        cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=self.seed)

        for _, (train, test) in zip(tqdm(range(self.len)),cv.split(self.x, self.y)):
            start = time.time()
            self.estimator.fit(self.x.iloc[train,:], self.y.iloc[train])
            end = time.time()
            time_list.append(end-start)
            pred_proba = self.estimator.predict_proba(self.x.iloc[test,:])
            pred = self.estimator.predict(self.x.iloc[test,:])
            confusion_matrixs_sum += metrics.confusion_matrix(self.y.iloc[test], pred)
            kwargs_func_scores = {'roc_auc': {'y_score':pred_proba[:,1]}, 'accuracy': {'y_pred':pred}, 'f1': {'y_pred':pred, 'average':'macro'},
                                     'precision': {'y_pred':pred, 'average':'macro'},'recall': {'y_pred':pred, 'average':'macro'}}
            for metric in scoring:
                score = getattr(metrics, f'{metric}_score')(self.y.iloc[test], **kwargs_func_scores[metric])  
                self.scores[metric].append(score)
                
            fpr, tpr, _ = metrics.roc_curve(self.y.iloc[test], pred_proba[:,1])
            interp_tpr = np.interp(self.fpr_mean, fpr, tpr)
            interp_tpr[0] = 0.0
            tprs.append(interp_tpr)
        
        self.confusion_matrix_mean = confusion_matrixs_sum / self.len
        self.means = dict(map(lambda kv: (kv[0], np.mean(kv[1],axis=0)), self.scores.items()))
        self.stds = dict(map(lambda kv: (kv[0], np.std(kv[1],ddof=1)), self.scores.items()))
        self.time_mean = np.mean(time_list,axis=0)
        
        self.tprs_mean = np.mean(tprs, axis=0)
        self.tprs_std = np.std(tprs, axis=0, ddof=1)
        if report:
            self.report()

    def report(self):
        '''
        Imprime os resultados da validação cruzada
        '''
        tp = self.confusion_matrix_mean[1][1]
        fp = self.confusion_matrix_mean[0][1]
        fn = self.confusion_matrix_mean[1][0]
        tn = self.confusion_matrix_mean[0][0]
        
        More_less = u"\u00B1"
        
        print(f'{self.n_repeats} repetições de Validação Cruzada com {self.n_splits} divisões no dataset')
        print(f'----------------------------------------------------------------------------------')
        print(f'CLASSIFICADOR                           : {self.estimator}')
        print(f'----------------------------------------------------------------------------------')
        print(f'Métricas no dataset de teste:           ')
        print(f'Intervalo de 95% da média            |   Média por classe')
        print(f'-------------------------------------|--------------------------------------------')
        print(r'ROC AUC MÉDIA      : %0.3f %s %0.3f   |  ' %\
             (np.round(self.means['roc_auc'],3), More_less, np.round(norm.ppf(0.975) * self.stds['roc_auc'] / np.sqrt(self.len),3)))
        print(f'ACURÁCIA  MÉDIA    : %0.3f %s %0.3f   |' %\
             (np.round(self.means['accuracy'],3), More_less, np.round(norm.ppf(0.975) * self.stds['accuracy'] / np.sqrt(self.len),3)))
        print(f'-------------------------------------|--------------------------------------------')
        print(f'                      MÉDIA MACRO    |CLASSE 0  |CLASSE 1')
        print(f'----------------------------------------------------------------------------------')
        print(f'PRECISÃO  MÉDIA    : %0.3f %s %0.3f   |%0.3f     |%0.3f    '%\
                  (np.round(self.means['precision'],3), More_less, np.round(norm.ppf(0.975) * self.stds['precision'] / np.sqrt(self.len),3),
                   np.round(tn/(tn+fn),3),np.round(tp/(tp+fp),3)))
        print(f'RECALL MÉDIO       : %0.3f %s %0.3f   |%0.3f     |%0.3f     '%\
                  (np.round(self.means['recall'],3), More_less, np.round(norm.ppf(0.975) * self.stds['recall'] / np.sqrt(self.len),3),
                   np.round(tn/(tn+fp),3), np.round(tp/(tp+fn),3)))
                
        print(f'F1-SCORE  MÉDIO    : %0.3f %s %0.3f   |%0.3f     |%0.3f    '%\
                  (np.round(self.means['f1'],3), More_less, np.round(norm.ppf(0.975) * self.stds['f1'] / np.sqrt(self.len),3),
                   np.round((2 * (tn/(tn+fn) * (tn/(tn+fp)))) / ((tn/(tn+fn)+(tn/(tn+fp)))), 3),
                   np.round((2 * (tp/(tp+fp) * (tp/(tp+fn)))) / ((tp/(tp+fp)+(tp/(tp+fn)))), 3)))
                   
        print(f'\nTEMPO MÉDIO DE TREINAMENTO:{np.round(self.time_mean,3)} segundos')   
    
    def plot_confusion(self,
                      ax=None,
                      labels_ticks = ['Não foi para UTI','Foi para UTI'],
                      name_estimator='',
                      **kwargs_heatmap):
        '''
        Plota um mapa de calor com os valores compuatados de verdadeiros positivos, falsos positivos,
        verdadeiros neagtivos e falsos negativos. Esses valores são obtidos através da média de diversas 
        matrizes de confusões geradas na validação cruzada. OBS: os valores foram aproximados para o 
        número inteiro mais próximo da média.
        
        Parâmetros:
        -----------
        ax : eixo a ser plotado o gráfico, se nenhum for passado será criado automaticamente, 
            tipo : matplotlib.axes, padrão : None
        labels_ticks : lista com os nomes das classificações 0 e 1, para serem plotadas nos eixos, 
            tipo : list, padrão :['Não foi para UTI','Foi para UTI']
        name_estimator: Nome do modelo que aparece no título do gráfico, 
                        se nenhum for passado será imprimido como o modelo foi instanciado, tipo : str, padrão : None
        **kwargs_heatmap : argumentos adicionais a serem passados para função heatmap do seaborn
        
        Retorno:
        --------
        ax : Retorna o eixo do matplotlib onde foi gerado o gráfico
        '''

        if ax == None:
            fig, ax = plt.subplots(figsize = (16,12))
        if name_estimator == '':
            name_estimator = self.estimator

        plt.sca(ax)
        sns.heatmap(self.confusion_matrix_mean.round(), annot=True, 
                    cmap='Blues', annot_kws={"fontsize":30}, **kwargs_heatmap)
        labs(title=f'Matriz de confusão do modelo {name_estimator}', 
             ax=ax, xlabel='VALORES PREVISTOS', ylabel='VALORES REAIS',
             subtitle=f'VALORES CALCULADOS PELA APROXIMAÇÃO DA MÉDIA DA MATRIZ DE CONFUSÃO NA VALIDAÇÃO CRUZADA COM {self.n_repeats} REPETIÇÕES E COM {self.n_splits} DIVISÕES NO DATASET')
        
        plt.xticks(np.arange(0.5,2), labels_ticks)
        plt.yticks(np.arange(0.5,2), labels_ticks)
        cbar = ax.collections[0].colorbar
        cbar.ax.tick_params(labelsize=20)
        return ax
        

    def hist_metrics(self, 
                    central:bool=True, 
                    bins:int=5,
                    name_estimator:str=None,
                    **kwargs_histplot):
        '''
        Plota os histogramas das métricas calculadas pela validação cruzada na função cross_val()
        
        Parâmetros:
        -----------
        central : booleano indicando se é para plotar a média e a mediana das métricas no histograma, 
                tipo : bool, padrão : True, 
        bins : quantidade de barras do histograma, tipo : int, padrão : 5
        **kwargs_histplot : argumentos adicionais a serem passados para função lineplot do seaborn
        name_estimator: Nome do modelo que aparece no título do gráfico, 
                        se nenhum for passado será imprimido como o modelo foi instanciado, tipo : str, padrão : None
        Retorno:
        --------
        ax : Retorna o eixo do matplotlib onde foi gerado o gráfico
        
        '''
        fig, ax = plt.subplots(ceil(len(self.scores)/2),2, figsize = (20, int(8*len(self.scores)/2)),
                              sharex=True, sharey=True)
        i=0
        j=0
        for k, v in self.scores.items():
            if len(v) == 0:
                pass
            
            else:
                plt.sca(ax[i,j])
                sns.histplot(v, bins=bins, **kwargs_histplot)
                labs(title=k.upper() + ' SCORE',xlabel='Valor da métrica',ylabel='Frequência', ax=ax[i,j])
                ax[i,j].get_yaxis().set_major_locator(MaxNLocator(integer=True))
                ax[i,j].xaxis.set_tick_params(labelbottom=True, labelsize =15)
                if central:
                    central_trend(v, ax[i,j])
                if j == 1:
                    j = 0
                    i += 1
                else:
                    j+=1

        if j == 1:
            plt.delaxes(ax= ax[-1][1])
            pos1 = ax[-1][0].get_position() 
            ax[-1][0].set_position([pos1.x0 + 0.2, pos1.y0, pos1.width, pos1.height])

        if name_estimator == None:
            name_estimator = str(self.estimator)
        ax[0,0].text(0,1.18,f'Distribuição dos desempenhos do modelo {name_estimator}', 
                     fontsize=25, transform=ax[0,0].transAxes)
        ax[0,0].text(0,1.12,'MÉTRICAS OBTIDAS PELO MÉTODO REPEATEDSTRATIFIEDKFOLD', 
                     fontsize=15, transform=ax[0,0].transAxes, color='gray')
        return ax

    def plot_roc_curve(self, 
                      ax=None, 
                      name_estimator:str=None,
                      **kwargs_lineplot):

        '''
        Plota a curva ROC construída pelos tprs e fprs calculados na validação cruzada pela função cross_val() 
        
        Parâmetros:
        -----------
        ax : eixo a ser plotado o gráfico, se nenhum for passado será criado automaticamnete, tipo : matplotlib.axes, padrão : None
        name_estimator: Nome do modelo que aparece na legenda do gráfico, se nenhum for passado será imprimido 
                        como o modelo foi instanciado, tipo : str, padrão : None
        **kwargs_lineplot : argumentos adicionais a serem passados para função lineplot do seaborn
        
        Retorno:
        --------
        ax : Retorna o eixo do matplotlib onde foi gerado o gráfico
        '''
        if ax == None:
            first=True
            fig,ax = plt.subplots(figsize=(20,10))
        else:
            first=False
        
        if name_estimator == None:
            name_estimator = str(self.estimator)
        
        sns.lineplot(self.fpr_mean, self.tprs_mean, ax=ax, label= r'CURVA ROC (MÉDIA AUC = %0.3f $\pm$ %0.3f)' % \
                         (np.round(self.means['roc_auc'],3), np.round(norm.ppf(0.975) * self.stds['roc_auc'] / np.sqrt(self.len),3)) + f'{name_estimator}', estimator=None, **kwargs_lineplot)
        plt.sca(ax)
        
        tprs_upper = np.minimum(self.tprs_mean + norm.ppf(0.975) * self.tprs_std / np.sqrt(self.len), 1)
        tprs_lower = np.maximum(self.tprs_mean - norm.ppf(0.975) * self.tprs_std / np.sqrt(self.len), 0)
        plt.fill_between(self.fpr_mean, tprs_lower, tprs_upper, color=ax.lines[-1].get_color(), alpha=0.05)
        
        if first:
            labs(title = 'CURVA ROC', xlabel='Taxa de Falsos Positivos', ylabel='Taxa de Verdadeiros Positivos', ax=ax, \
                     subtitle='CURVA ROC COMPUTADA PELOS VALORES DE VERDADEIROS POSITIVOS E FALSOS POSITIVOS OBTIDOS NA VALIDAÇÃO CRUZADA')
        plt.legend(loc='lower right', fontsize=12)
        return ax